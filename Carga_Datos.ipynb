{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pyeeg as pe\n",
    "import pickle as pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Definimos los canales que queremos analizar, en este caso son los 8 canales de un sistema OpenBCI\n",
    "canales = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "# Las etiquetas en el comentario (Fp1, Fp2, C3, C4, etc.) indican las posiciones correspondientes de los electrodos EEG.\n",
    "\n",
    "# Frecuencias de las bandas para obtener la Densidad Espectral de Potencia (PSD)\n",
    "banda = [.5, 4, 8, 12, 30, 45]\n",
    "# Estas representan las diferentes bandas de frecuencia para analizar los datos EEG:\n",
    "# - Delta: de 0.5 Hz a 4 Hz\n",
    "# - Theta: de 4 Hz a 8 Hz\n",
    "# - Alpha: de 8 Hz a 12 Hz\n",
    "# - Beta: de 12 Hz a 30 Hz\n",
    "# - Gamma Baja: de 30 Hz a 45 Hz\n",
    "# - Gamma Alta: por encima de 45 Hz\n",
    "\n",
    "# División de tiempo para crear épocas de 2 segundos (downsampleado a 128 Hz)\n",
    "tamano_ventana = 128 * 5 # Cada época tendrá una duración de 5 segundos (128 muestras por segundo * 5 segundos)\n",
    "\n",
    "# Actualización del tiempo en ciertos pasos\n",
    "tamaño_paso = 16 # La actualización se realiza cada 0.125 segundos (16 muestras por segundo)\n",
    "\n",
    "# Tasa de muestreo de los datos EEG\n",
    "tasa_muestreo = 128 # Los datos EEG se muestrean a 128 Hz (128 muestras por segundo)\n",
    "\n",
    "# Para cargar todos los datos de los sujetos\n",
    "lista_sujetos = ['01', '02', '03', ..., '32'] # Lista de sujetos (presumiblemente datos EEG de 32 sujetos diferentes)\n",
    "# Reemplaza '...' con los códigos reales de los sujetos (por ejemplo, '01', '02', '03', etc.)\n",
    "\n",
    "# Definimos una función para obtener las bandas EEG mediante el procesamiento de la Transformada Rápida de Fourier (FFT)\n",
    "def Procesamiento_FFT(sub, canales, banda, tamano_ventana, tamaño_paso, tasa_muestreo):\n",
    "    # Variable para almacenar los metadatos para cada época\n",
    "    meta = []\n",
    "\n",
    "    # Abrimos y leemos los datos EEG usando pickle\n",
    "    with open('datos\\s' + sub + '.dat', 'rb') as archivo:\n",
    "        sujeto = pickle.load(archivo, encoding='latin1')\n",
    "\n",
    "        for i in range(0, 40):\n",
    "            datos = sujeto[\"data\"][i] # Datos EEG para una prueba específica\n",
    "            etiquetas = sujeto[\"labels\"][i] # Etiquetas para cada paso de tiempo de la prueba\n",
    "            inicio = 0\n",
    "\n",
    "            # Iteramos sobre los datos de la prueba con los tamaños de ventana y paso especificados\n",
    "            while inicio + tamano_ventana < datos.shape[1]:\n",
    "                meta_array = []\n",
    "                meta_data = [] # Vector meta para el análisis de potencia de banda\n",
    "\n",
    "                # Iteramos sobre los canales EEG especificados para el análisis\n",
    "                for j in canales:\n",
    "                    X = datos[j][inicio : inicio + tamano_ventana] # Segmentamos los datos crudos durante 5 segundos\n",
    "                    Y = pe.bin_power(X, banda, tasa_muestreo) # Calculamos la Densidad Espectral de Potencia (PSD) para la ventana actual\n",
    "                    meta_data = meta_data + list(Y[0]) # Agregamos los valores de PSD al vector meta_data\n",
    "\n",
    "                meta_array.append(np.array(meta_data)) # Convertimos meta_data en un array y lo agregamos a meta_array\n",
    "                meta_array.append(etiquetas) # Agregamos la etiqueta correspondiente a meta_array\n",
    "\n",
    "                meta.append(np.array(meta_array)) # Convertimos meta_array en un array y lo agregamos a la lista meta\n",
    "                inicio = inicio + tamaño_paso # Movemos la ventana utilizando el tamaño de paso especificado\n",
    "\n",
    "        # Convertimos la lista meta en un array NumPy para un procesamiento adicional\n",
    "        meta = np.array(meta)\n",
    "\n",
    "        # Guardamos los datos procesados del sujeto en un archivo usando la función de guardado de NumPy\n",
    "        np.save('out\\s' + sub, meta, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "# Listas para almacenar datos de los conjuntos de entrenamiento, prueba y validación\n",
    "datos_entrenamiento = []\n",
    "etiquetas_entrenamiento = []\n",
    "datos_prueba = []\n",
    "etiquetas_prueba = []\n",
    "datos_validacion = []\n",
    "etiquetas_validacion = []\n",
    "\n",
    "# Cambiamos el comportamiento de carga de NumPy para allow_pickle=True\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# Iteramos sobre cada sujeto en la lista de sujetos\n",
    "for sujeto in lista_sujetos:\n",
    "    # Cargamos los datos procesados del sujeto\n",
    "    with open(os.path.join('out', f's{sujeto}.npy'), 'rb') as archivo:\n",
    "        sub = np.load(archivo, allow_pickle=True)\n",
    "\n",
    "        # Iteramos sobre cada época en los datos del sujeto\n",
    "        for i in range(sub.shape[0]):\n",
    "            if i % 8 == 0:\n",
    "                datos_prueba.append(sub[i][0])\n",
    "                etiquetas_prueba.append(sub[i][1])\n",
    "            elif i % 8 == 1:\n",
    "                datos_validacion.append(sub[i][0])\n",
    "                etiquetas_validacion.append(sub[i][1])\n",
    "            else:\n",
    "                datos_entrenamiento.append(sub[i][0])\n",
    "                etiquetas_entrenamiento.append(sub[i][1])\n",
    "\n",
    "# Restauramos el comportamiento de carga original de NumPy\n",
    "np.load = np_load_old\n",
    "\n",
    "# Guardamos los conjuntos de entrenamiento, prueba y validación en archivos separados\n",
    "np.save(os.path.join('out', 'datos_entrenamiento.npy'), np.array(datos_entrenamiento), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'etiquetas_entrenamiento.npy'), np.array(etiquetas_entrenamiento), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'datos_prueba.npy'), np.array(datos_prueba), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'etiquetas_prueba.npy'), np.array(etiquetas_prueba), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'datos_validacion.npy'), np.array(datos_validacion), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'etiquetas_validacion.npy'), np.array(etiquetas_validacion), allow_pickle=True, fix_imports=True)\n",
    "\n",
    "# Imprimimos las formas de los conjuntos de entrenamiento, prueba y validación resultantes\n",
    "print(\"Conjunto de entrenamiento:\", np.array(datos_entrenamiento).shape, np.array(etiquetas_entrenamiento).shape)\n",
    "print(\"Conjunto de prueba:\", np.array(datos_prueba).shape, np.array(etiquetas_prueba).shape)\n",
    "print(\"Conjunto de validación:\", np.array(datos_validacion).shape, np.array(etiquetas_validacion).shape)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
