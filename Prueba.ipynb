{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos las librerias necesarias\n",
    "import numpy as np #manipulacion matematica\n",
    "import pickle as pickle #para descomprimir archivos\n",
    "import pandas as pd #manipulacion de dataframes\n",
    "import math #math\n",
    "import matplotlib.pyplot as plt\n",
    "import pyeeg as pe\n",
    "\n",
    "import os #comunicacion con equipo operativo\n",
    "import time #control de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos los canales que queremos, en este caso son los 8 de openbci\n",
    "channel = [1, 17, 7, 25, 12, 30, 14, 32] #Fp1, Fp2, C3, C4 25, P7, P8, O1, O2\n",
    "\n",
    "#frecuencias de las bandas para obtener los psds\n",
    "band = [.5,4,8,13,30,45] #5 bands\n",
    "\n",
    "#division de tiempos para que dure 2 segundos (downsampleado a 128 hz)\n",
    "window_size = 128*5 #Averaging band power of 5 sec\n",
    "\n",
    "#update para el tiempo cada ciertos pasos\n",
    "step_size = 16 #Each 0.125 sec update once\n",
    "\n",
    "#frecuencia de muestreo\n",
    "sample_rate = 128 #Sampling rate of 128 Hz\n",
    "\n",
    "#para cargar todos los datos\n",
    "subjectList = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32'] #List of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#definimos funcion para obtener las bandas, se pide lo siguiente:\n",
    "# sub = el numero de sujeto\n",
    "# channel = el canal de eeg\n",
    "# band = la frecuencia para la divicion de bandas\n",
    "# window size = el tamaño de la ventana para entrenar\n",
    "# step size = el tamaño de paso que se da\n",
    "# sample rate = frecuencia de muestreo\n",
    "\n",
    "def FFT_Processing (sub, channel, band, window_size, step_size, sample_rate):\n",
    "    #guarda los metadatos\n",
    "    meta = []\n",
    "\n",
    "# abre todos los datos usando pickle para descomprimir\n",
    "    with open('datos\\s' + sub + '.dat', 'rb') as file:\n",
    "\n",
    "        subject = pickle.load(file, encoding='latin1') #resolve the python 2 data problem by encoding : latin1\n",
    "\n",
    "        for i in range (0,40):\n",
    "            # para las 40 pruebas realizadas\n",
    "            data = subject[\"data\"][i] \n",
    "            labels = subject[\"labels\"][i]\n",
    "            start = 0\n",
    "\n",
    "            while start + window_size < data.shape[1]:\n",
    "                meta_array = []\n",
    "                meta_data = [] #meta vector for analysis\n",
    "                for j in channel:\n",
    "                    X = data[j][start : start + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
    "                    Y = pe.bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
    "                    meta_data = meta_data + list(Y[0])\n",
    "\n",
    "                meta_array.append(np.array(meta_data))\n",
    "                meta_array.append(labels)\n",
    "\n",
    "                meta.append(np.array(meta_array))    \n",
    "                start = start + step_size\n",
    "                \n",
    "        meta = np.array(meta)\n",
    "        np.save('out\\s' + sub, meta, allow_pickle=True, fix_imports=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-1f4853850be8>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  meta.append(np.array(meta_array))\n"
     ]
    }
   ],
   "source": [
    "for subjects in subjectList:\n",
    "    FFT_Processing (subjects, channel, band, window_size, step_size, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset: (445440, 40) (445440, 4)\n",
      "testing dataset: (74240, 40) (74240, 4)\n",
      "validation dataset: (74240, 40) (74240, 4)\n"
     ]
    }
   ],
   "source": [
    "#for subjects in subjectList:\n",
    "data_training = []\n",
    "label_training = []\n",
    "data_testing = []\n",
    "label_testing = []\n",
    "data_validation = []\n",
    "label_validation = []\n",
    "\n",
    "np_load_old = np.load #no tocar\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k) #no tocar\n",
    "\n",
    "for subjects in subjectList:\n",
    "\n",
    "    with open('out\\s' + subjects + '.npy', 'rb') as file:\n",
    "        sub = np.load(file)\n",
    "        for i in range (0,sub.shape[0]):\n",
    "            if i % 8 == 0:\n",
    "                data_testing.append(sub[i][0])\n",
    "                label_testing.append(sub[i][1])\n",
    "            elif i % 8 == 1:\n",
    "                data_validation.append(sub[i][0])\n",
    "                label_validation.append(sub[i][1])\n",
    "            else:\n",
    "                data_training.append(sub[i][0])\n",
    "                label_training.append(sub[i][1])\n",
    "\n",
    "np.save('out\\data_training', np.array(data_training), allow_pickle=True, fix_imports=True)\n",
    "np.save('out\\label_training', np.array(label_training), allow_pickle=True, fix_imports=True)\n",
    "print(\"training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
    "\n",
    "np.save('out\\data_testing', np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
    "np.save('out\\label_testing', np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
    "print(\"testing dataset:\", np.array(data_testing).shape, np.array(label_testing).shape)\n",
    "\n",
    "np.save('out\\data_validation', np.array(data_validation), allow_pickle=True, fix_imports=True)\n",
    "np.save('out\\label_validation', np.array(label_validation), allow_pickle=True, fix_imports=True)\n",
    "print(\"validation dataset:\", np.array(data_validation).shape, np.array(label_validation).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALAS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
